# -*- coding: utf-8 -*-
"""Scholarship Award Decision Using Deep Learnin.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x5ftN0pg6V07CeubhXbN6yctjNXYshix
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings("ignore")

sns.set_palette("rocket")

from sklearn.preprocessing import OrdinalEncoder

from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

import joblib

from google.colab import drive
drive.mount('/content/drive')
dataset_path = "/content/drive/MyDrive/ScholarshipAwardDecisionTool/"
scholarship_df = pd.read_excel(dataset_path + "dataset_combined.xlsx", engine='openpyxl')

scholarship_df.head(3)

"""# Exploratory Data Analysis

"""

# Basic statistics of the dataset
print(scholarship_df.describe())

# Information about the dataset
print(scholarship_df.info())

# Display column names
print(scholarship_df.columns)

# Unique value counts for each column to understand distributions
for col in scholarship_df.columns:
    print(scholarship_df[col].value_counts())
    print("-" * 100)

"""# Helper function for analyzing feature relationships"""

def get_graph_data(scholarship_df, feature_col):
    df_0 = scholarship_df[scholarship_df["Outcome"] == 0][[feature_col, "Outcome"]].groupby(feature_col).count().reset_index()
    df_1 = scholarship_df[scholarship_df["Outcome"] == 1][[feature_col, "Outcome"]].groupby(feature_col).count().reset_index()

    df = pd.DataFrame()
    df[feature_col] = df_0[feature_col]
    df["Outcome=0"] = df_0["Outcome"]
    df["Outcome=1"] = df_1["Outcome"]
    df["Outcome_Total"] = df["Outcome=0"] + df["Outcome=1"]
    df["Outcome=0 %"] = (df["Outcome=0"] / df["Outcome_Total"]) * 100
    df["Outcome=1 %"] = (df["Outcome=1"] / df["Outcome_Total"]) * 100

    return df

"""# Relationships for Key Features

# For Education Qualification
"""

# For Education Qualification
df_education = get_graph_data(scholarship_df, "Education Qualification")
sns.barplot(data=df_education, x="Education Qualification", y="Outcome=1 %").set_title("Education vs Scholarship Approval")
plt.show()

"""# For Gender

"""

df_gender = get_graph_data(scholarship_df, "Gender")
sns.barplot(data=df_gender, x="Gender", y="Outcome=1 %").set_title("Gender vs Scholarship Approval")
plt.show()

"""# For Income"""

df_income = get_graph_data(scholarship_df, "Income")
sns.barplot(data=df_income, x="Income", y="Outcome=1 %").set_title("Income vs Scholarship Approval")
plt.show()

"""# Data Cleaning and Encoding"""

# Drop features irrelevant to the Kenyan context
scholarship_df = scholarship_df.drop(["Name", "Religion", "Exservice-men"], axis=1)

"""# Encode ordinal features"""

# Encode ordinal features
def ordinal_encoding(dataframe, col_name, categories, new_col_name):
    enc = OrdinalEncoder(categories=[categories])
    categories = pd.Categorical(dataframe[col_name], categories=categories, ordered=True)
    labels, unique = pd.factorize(categories, sort=True)
    dataframe[new_col_name] = labels
    return dataframe

"""# Encoding Education Qualification (Undergraduate, Diploma, Postgraduate)

"""

# Encoding Education Qualification (Undergraduate, Diploma, Postgraduate)
categories = ["Undergraduate", "Diploma", "Postgraduate"]
scholarship_df = ordinal_encoding(scholarship_df, "Education Qualification", categories, "Education_Qualification")

# Encoding Income levels specific to Kenya
categories = ["Below 200K", "200K-500K", "500K-1M", "Above 1M"]
scholarship_df = ordinal_encoding(scholarship_df, "Income", categories, "Income_Level")

# Encode categorical (nominal) features
def nominal_encoding(dataframe, col_name):
    return pd.get_dummies(dataframe, columns=[col_name])

# Encode categorical (nominal) features
def nominal_encoding(dataframe, col_name):
    return pd.get_dummies(dataframe, columns=[col_name])

scholarship_df = nominal_encoding(scholarship_df, "Gender")
scholarship_df = nominal_encoding(scholarship_df, "Disability")
scholarship_df = nominal_encoding(scholarship_df, "Sports")

# Drop original columns after encoding
scholarship_df = scholarship_df.drop(["Education Qualification", "Income"], axis=1)
scholarship_df

"""# Data Splitting and Scaling"""

# Separate features (X) and target variable (y)
y = scholarship_df["Outcome"]
X = scholarship_df.drop("Outcome", axis=1)
non_numeric_columns = X.select_dtypes(include=['object']).columns
X = X.drop(non_numeric_columns, axis=1)

# Standardize numerical features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""# Split data into training and test sets

"""

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Neural Network Model
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam

"""# Define the model architecture

"""

model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(32, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)

# Evaluate the model on test data
results = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Loss: {results[0]}, Test Accuracy: {results[1]}")

# Predictions
y_pred = model.predict(X_test)
y_pred = np.round(y_pred).astype(int).flatten()

"""# Performance Metrics"""

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues')
plt.show()

# Classification Report
print(classification_report(y_test, y_pred))

# Accuracy and Loss over epochs
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.legend()
plt.title('Model Accuracy')
plt.show()

plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.legend()
plt.title('Model Loss')
plt.show()

# Save the model
model.save("kenya_scholarship_model.h5")

